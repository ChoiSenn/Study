# VGG-16 논문 번역 및 읽기 
## 2022-09-13
<VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION >
 
 https://arxiv.org/pdf/1409.1556.pdf%20http://arxiv.org/abs/1409.1556.pdf

## 초록
 이 논문에서, 우리는 대규모 이미지 인식(large-scale image)에서 합성곱 신경망(convolutional network)의 깊이가 (예측) 정확도에 미치는 영향을 조사한다. 우리의 주요 기여는 매우 작은 크기(3x3) 크기의 합성곱(convolution) 필터를 이용한 네트워크의 깊이를 증가시키는 과정을 철처히 조사(감정)하여, 깊이(depth)를 16~19의 가중치까지 밀어냄으로써 선행 기술 구성에 대한 상당한 개선이 달성될 수 있음을 보여주는 것이다. 이러한 결과는 ImageNet Challenge 2014의 제출물의 기반이 되었으며, 우리의 팀은 위치 측정(localisation) 및 분류 부문에서 각각 1위와 2위를 달성하였다. 또한, 우리의 이러한 방법(representations)이 다른 데이터 세트에서도 좋은 결과(state-of-the-art)를 달성하는데 효과적이라는 것을(일반화) 보여준다. 우리는 컴퓨터 비전에서의 심층 시각적 표현 사용에 대한 추후 연구를 용이하게 하기 위해 두 가지의 최고 성능의 ConvNet 모델을 만들어 공개적으로 사용할 수 있게 했다.

  ## 내용 정리
  VGG 모델은 AlexNet의 8-레이어 모델보다 깊이가 두 배 이상 깊은 네트워크의 학습에 성공했으며, 이를 통해 ImageNet 대회에서 AlexNet의 오류율에서 절반의 오류율(16.4에서 7.3)을 기록했다.
 
  이처럼 VGG 모델이 16~19 레이어에 달하는 깊은 신경망을 학습할 수 있었던 것은 모든 합성곱 레이어에서 3 x 3 필터를 사용했기 때문이다.
 
  64, 128, 256, 512 개의 3x3 필터를 학습 매개변수로 사용해가며 신경망의 성능을 테스트하였다. 또한, 신경망의 마지막 부분인 three Fully-Connected Layer는 각각 4096, 4096, 1000 개의 유닛으로 구성되어 있으며, 출력층은 분류를 위해 Softmax 함수를 사용하였다.
 
 
 VGG 모델 이전에 합성곱 신경망을 활용해 이미지 분류를 했던 모델들은 비교적 큰 수용장(Receptive Field)을 갖는 11x11이나 7x7 필터를 포함한다. 그러나 VGG 모델은 매우 작은 3x3 필터만 사용하여 정확한 이미지 분류를 수행했다.

 3x3 필터만 이용했을 경우에도 three-layer Convolusion을 반복하면 원본 이미지의 7x7에 해당하는 영역을 수용할 수 있다. 즉, 스트라이드가 1일 때, 세 차례의 3x3 합성곱 필터링을 반복한 맵은 한 픽셀이 원본의 7x7 수용장의 효과를 볼 수 있다.
 
 3x3 필터로 Convolution을 세 차례 반복 수행했을 때

 : 결정 함수의 비선형성이 증가한다. 각 합성곱 연산은 ReLU 함수를 포함한다. 즉, 1-레이어 7x7 필터링의 경우에는 한 번의 비선형 함수만 적용되지만, 3-레이어 3x3 필터링의 경우에는 세 번의 비선형 함수가 적용된다. 따라서 모델의 특징 식별성이 증가한다.
 : 학습 파라미터의 수가 감소한다. 학습 대상인 가중치(weight)는 필터의 크기에 해당한다. 따라서 1-레이어 7x7 필터의 학습 파라미터 수는 49개이고, 3-레이어 3x3 필터의 학습 파라미터 수는 27개로 감소한 모습이다.
 
 
## 용어 정리
 
 번역 시, 용어들은 대부분 익숙한 용어였지만 한국말로 치환하기 어려운 부분이 많았다. 완전히 언어를 옮겨서 번역하기보다는 용어 자체의 뜻을 정확히 파악하도록 노력하는 것이 좋다.
 
 
 Convolutional Network : 
 
 Receptive Field : 
 
 bounding box : 
 
 stride : 
